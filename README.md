# Система классификации изображений

## Обзор
Этот проект реализует интеллектуальную систему классификации и поиска похожих изображений, используя комбинацию передовых моделей искусственного интеллекта, включая ConvNext и Qwen2-VL. Система обеспечивает как визуальное сопоставление схожести, так и семантическое понимание для классификации и рекомендации изображений.

### Ключевые особенности
- Поддержка нескольких моделей ИИ (ConvNext для визуальных признаков, Qwen2-VL для семантического понимания)
- Обработка и классификация изображений в реальном времени
- Интерактивный веб-интерфейс для загрузки изображений и визуализации результатов
- Рекомендации на основе схожести изображений
- Продвинутая визуализация результатов сопоставления
- Функционал экспорта результатов анализа
- Настраиваемые пороги и параметры сопоставления
- Панель статистики и аналитики

## Структура проекта
```
image-classifier/
├── backend/
│   ├── app.py                 # Реализация FastAPI сервера
│   ├── vision_process.py      # Утилиты обработки изображений
│   ├── convnext_init.py       # Инициализация модели ConvNext
│   └── requirements.txt       # Python зависимости
├── frontend/
│   ├── package.json          # Node.js зависимости
│   ├── tailwind.config.js    # Конфигурация Tailwind CSS
│   ├── src/
│   │   ├── App.jsx          # Основной компонент приложения
│   │   └── components/
│   │       └── ImageClassifier.jsx  # Основной UI компонент
│   └── public/
├── jupyter_notebooks/        # Jupyter ноутбуки с экспериментами
│   ├── 01_data_preparation.ipynb     # Подготовка данных
│   ├── 02_model_training.ipynb       # Обучение моделей
│   ├── 03_feature_extraction.ipynb   # Извлечение признаков
│   └── 04_evaluation.ipynb           # Оценка результатов
└── dataset/
    └── [папки категорий]    # Организованный набор изображений
```

## Руководство по установке

### Предварительные требования
- Python 3.8+
- Node.js 14+
- GPU с поддержкой CUDA (рекомендуется для оптимальной производительности)
- 8GB+ оперативной памяти
- 20GB+ свободного места на диске

### Настройка бэкенда

1. Создайте и активируйте виртуальное окружение Python:
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
.\venv\Scripts\activate  # Windows
```

2. Установите зависимости бэкенда:
```bash
cd backend
pip install -r requirements.txt
```

3. Необходимые Python пакеты (requirements.txt):
```
fastapi==0.100.0
uvicorn==0.22.0
python-multipart==0.0.6
pillow==10.0.0
torch==2.0.1
transformers==4.30.2
numpy==1.24.3
annoy==1.17.1
python-jose==3.3.0
tqdm==4.65.0
```

4. Загрузка весов моделей:
```bash
# Система автоматически загрузит необходимые веса моделей при первом запуске
# Убедитесь, что у вас есть ~10GB свободного места для файлов моделей
```

### Настройка фронтенда

1. Создайте и настройте React проект:
```bash
npx create-react-app frontend
cd frontend
```

2. Установите необходимые пакеты:
```bash
# Основные зависимости
npm install -D tailwindcss postcss autoprefixer
npm install @headlessui/react @heroicons/react
npm install lucide-react
npm install recharts

# UI компоненты
npm install @/components/ui/alert
npm install @/components/ui/card
```

3. Инициализируйте Tailwind CSS:
```bash
npx tailwindcss init -p
```

4. Настройте Tailwind (tailwind.config.js):
```javascript
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    "./src/**/*.{js,jsx,ts,tsx}",
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}
```

5. Добавьте директивы Tailwind (src/index.css):
```css
@tailwind base;
@tailwind components;
@tailwind utilities;
```

## Конфигурация

### Конфигурация бэкенда

1. Переменные окружения:
```bash
# Создайте файл .env в директории backend
MODEL_PATH=/path/to/models    # Опционально: Путь к весам моделей
CUDA_VISIBLE_DEVICES=0       # Опционально: Указание GPU устройства
MAX_BATCH_SIZE=16           # Опционально: Размер пакета обработки
```

2. Настройка CORS (app.py):
```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

### Конфигурация фронтенда

1. Настройка API:
```javascript
// src/config.js
export const API_URL = 'http://localhost:8000';
export const BATCH_SIZE = 10;
export const DEFAULT_SIMILARITY_THRESHOLD = 0.3;
```

## Запуск системы

### Запуск сервера бэкенда
```bash
cd backend
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

### Запуск сервера разработки фронтенда
```bash
cd frontend
npm start
```

Приложение будет доступно по адресам:
- Фронтенд: http://localhost:3000
- API бэкенда: http://localhost:8000
- Документация API: http://localhost:8000/docs

## Руководство по использованию

### Обработка изображений
1. Откройте веб-интерфейс по адресу http://localhost:3000
2. Загрузите изображения через drag-and-drop или выбор файлов
3. При необходимости настройте параметры обработки:
   - Порог схожести
   - Уверенность классификации
   - Правила сопоставления категорий
4. Нажмите "Process Images" для начала анализа
5. Просмотрите результаты в интерактивном интерфейсе

### Интерпретация результатов
- **Визуальное совпадение**: Прямое сходство изображений (ConvNext)
- **Совпадение по категории**: Обнаружение схожей категории изображений
- **AI текстовый анализ**: Семантическое понимание (Qwen)

### Экспорт результатов
- Нажмите "Export CSV" для подробных данных анализа
- Используйте "Download Submission" для форматированных результатов
- Доступ к панели статистики для аналитики

## Оптимизация производительности

### Оптимизация бэкенда
- Использование GPU-ускорения при наличии
- Настройка размера пакета в зависимости от доступной памяти
- Настройка рабочих процессов для параллельной обработки

### Оптимизация фронтенда
- Сжатие изображений перед загрузкой
- Использование отложенной загрузки для превью
- Кэширование обработанных результатов

## Устранение неполадок

### Распространенные проблемы

1. Ошибки запуска бэкенда
```bash
# Проверка окружения Python
python --version
pip list

# Проверка установки CUDA (при использовании GPU)
python -c "import torch; print(torch.cuda.is_available())"
```

2. Проблемы подключения фронтенда
```bash
# Проверка доступности API
curl http://localhost:8000/status

# Проверка настроек CORS
# Проверьте консоль браузера на наличие ошибок CORS
```

3. Ошибки обработки
- Проверьте совместимость формата изображений
- Проверьте доступную системную память
- Убедитесь, что веса моделей загружены правильно

### Решения

1. Проблемы загрузки моделей:
```bash
# Очистка кэша моделей
rm -rf ~/.cache/torch/hub/
rm -rf ~/.cache/huggingface/
```

2. Проблемы с памятью:
```bash
# Уменьшение размера пакета в конфигурации
# Мониторинг системных ресурсов
top  # Linux/Mac
taskmgr  # Windows
```

## Руководство по разработке

### Добавление новых функций
1. Следуйте существующей структуре кода
2. Реализуйте обработку ошибок
3. Добавьте соответствующее логирование
4. Обновите документацию

### Тестирование
1. Запуск тестов бэкенда:
```bash
pytest backend/tests/
```

2. Запуск тестов фронтенда:
```bash
cd frontend
npm test
```

## Соображения безопасности

1. Валидация входных данных
- Реализация проверки типа файлов
- Ограничение размеров файлов
- Санитизация пользовательского ввода

2. Безопасность API
- Реализация ограничения частоты запросов
- Добавление аутентификации при необходимости
- Валидация параметров запросов

## Поддержка и обслуживание

### Логирование
- Логи бэкенда: `backend/logs/`
- Логи консоли фронтенда
- Статистика обработки в панели мониторинга

### Мониторинг
- Использование системных ресурсов
- Производительность обработки
- Частота и типы ошибок

## Jupyter ноутбуки

В папке `jupyter_notebooks` находятся исследовательские ноутбуки с различными экспериментами по поиску похожих изображений:

### 1. `only_convnext.ipynb`
Базовый подход с использованием только архитектуры ConvNeXT:
- Извлечение визуальных признаков с помощью ConvNeXT
- Создание и использование индекса Annoy для поиска похожих изображений
- Реализация простой стратегии голосования для определения категории
- Достигнутый MAP@10: 0.74-0.75

Основные компоненты:
- `ImageEncoder` класс для получения эмбеддингов
- Функции обработки датасета и создания индекса
- Расчет метрики MAP@10
- Визуализация результатов

### 2. `combined_emb.ipynb`
Улучшенный подход, комбинирующий визуальные и текстовые признаки:
- Использование ConvNeXT для визуальных признаков
- BLIP для генерации описаний изображений
- SentenceTransformer для получения текстовых эмбеддингов
- Конкатенация визуальных и текстовых эмбеддингов

Ключевые особенности:
- Генерация описаний изображений с помощью BLIP
- Создание комбинированных эмбеддингов
- Улучшенная стратегия поиска похожих изображений
- Анализ проблемных случаев и ошибок классификации

### 3. `make_submisson.ipynb`
Ноутбук для генерации финального сабмита:
- Оптимизированный пайплайн для обработки тестового датасета
- Стратегии обработки краевых случаев
- Форматирование выходных данных согласно требованиям
- Функции для создания CSV-файла с результатами

### 4. `vlm.ipynb`
Эксперименты с Vision Language Model (Qwen2-VL):
- Использование мультимодальной модели Qwen2-VL
- Получение контекстно-зависимых эмбеддингов
- Анализ внутренних представлений модели
- Прототипирование различных стратегий извлечения признаков

Особенности работы с VLM:
- Интеграция с HuggingFace Transformers
- Обработка изображений и текста
- Анализ hidden states и attention механизмов
- Возможности zero-shot классификации

### Запуск ноутбуков

```bash
# Создание окружения
python -m venv venv
source venv/bin/activate  # Linux/Mac
.\venv\Scripts\activate  # Windows

# Установка зависимостей
pip install -r requirements.txt

# Запуск Jupyter
jupyter lab
# или
jupyter notebook
```

### Требования к окружению
- Python 3.8+
- PyTorch 2.0+
- transformers
- sentence-transformers
- pillow
- numpy
- pandas
- matplotlib
- seaborn
- tqdm
- annoy

### Структура данных
Ноутбуки ожидают следующую структуру данных:
```
data/
├── train/
│   ├── category1/
│   │   ├── image1.jpg
│   │   └── image2.jpg
│   └── category2/
│       └── image3.jpg
├── valid/
└── test/
```

### Рекомендации по использованию
1. Начните с `only_convnext.ipynb` для понимания базового подхода
2. Изучите `combined_emb.ipynb` для более продвинутых техник
3. Используйте `vlm.ipynb` для экспериментов с мультимодальными моделями
4. Генерируйте финальные предсказания с помощью `make_submisson.ipynb`

## Лицензия
MIT License - См. файл LICENSE для подробностей

## Участие в разработке
1. Сделайте форк репозитория
2. Создайте ветку для новой функции
3. Отправьте pull request с описанием
4. Следуйте руководству по стилю кода
